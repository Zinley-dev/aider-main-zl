# Aider REST API

REST API cho Aider AI coding assistant, cho ph√©p t√≠ch h·ª£p Aider v√†o c√°c ·ª©ng d·ª•ng kh√°c.

## C√†i ƒë·∫∑t v√† Ch·∫°y

### 1. C√†i ƒë·∫∑t dependencies

```bash
# C√†i ƒë·∫∑t FastAPI v√† c√°c dependencies
pip install -r requirements_api.txt

# ƒê·∫£m b·∫£o Aider ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t
pip install -e .
```

### 2. C·∫•u h√¨nh API Keys

T·∫°o file `.env` trong th∆∞ m·ª•c g·ªëc:

```bash
# OpenAI API Key (cho GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (cho Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# DeepSeek API Key (cho DeepSeek models)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
```

### 3. Ch·∫°y API Server

```bash
python api_server.py
```

API s·∫Ω ch·∫°y t·∫°i `http://localhost:8000`

## API Documentation

### Swagger UI
Truy c·∫≠p `http://localhost:8000/docs` ƒë·ªÉ xem t√†i li·ªáu API t∆∞∆°ng t√°c.

### ReDoc
Truy c·∫≠p `http://localhost:8000/redoc` ƒë·ªÉ xem t√†i li·ªáu API d·∫°ng ReDoc.

## Endpoints Ch√≠nh

### 1. Health Check
```http
GET /health
```
Ki·ªÉm tra tr·∫°ng th√°i API.

### 2. T·∫°o Session
```http
POST /sessions
```
T·∫°o session m·ªõi ƒë·ªÉ chat v·ªõi Aider.

**Response:**
```json
{
  "session_id": "uuid-string",
  "message": "Session created successfully"
}
```

### 3. Chat v·ªõi Aider (H·ªó tr·ª£ Streaming)
```http
POST /chat
```

**Request Body:**
```json
{
  "message": "Your message to Aider",
  "session_id": "optional-session-id",
  "model": "gpt-4o",
  "files": ["file1.py", "file2.js"],
  "read_only_files": ["readme.md"],
  "edit_format": "whole",
  "stream": false
}
```

**Parameters:**
- `stream`: `true` ƒë·ªÉ enable Server-Sent Events (SSE) streaming, `false` cho response th√¥ng th∆∞·ªùng

**Response (Non-streaming):**
```json
{
  "response": "Aider's response",
  "edited_files": [
    {
      "name": "file1.py",
      "content": "updated file content"
    }
  ],
  "session_id": "session-uuid",
  "tokens_sent": 150,
  "tokens_received": 200,
  "cost": 0.0045,
  "output": "Tool output messages",
  "errors": "Error messages if any",
  "warnings": "Warning messages if any"
}
```

**Response (Streaming - SSE Format):**
```
event: start
data: {"message": "Starting chat..."}

event: processing
data: {"message": "Processing request..."}

event: tool_output
data: {"message": "Reading file: example.py"}

event: ai_output
data: {"message": "I'll help you add error handling..."}

event: file_write
data: {"filename": "example.py", "content_length": 1234, "success": true}

event: complete
data: {"response": "...", "edited_files": [...], "session_id": "...", "tokens_sent": 150, "tokens_received": 200, "cost": 0.0045}
```

**SSE Event Types:**
- `start`: B·∫Øt ƒë·∫ßu x·ª≠ l√Ω
- `info`: Th√¥ng tin chung
- `processing`: ƒêang x·ª≠ l√Ω request
- `tool_output`: Output t·ª´ tools
- `tool_error`: L·ªói t·ª´ tools
- `tool_warning`: C·∫£nh b√°o t·ª´ tools
- `ai_output`: Output t·ª´ AI model
- `assistant_output`: Output t·ª´ assistant
- `file_write`: Th√¥ng b√°o ghi file
- `response`: Response t·ª´ AI
- `complete`: Ho√†n th√†nh v·ªõi k·∫øt qu·∫£ cu·ªëi
- `heartbeat`: Heartbeat ƒë·ªÉ duy tr√¨ connection
- `error`: L·ªói x·∫£y ra

### 4. L·∫•y danh s√°ch Models
```http
GET /models
```

### 5. Qu·∫£n l√Ω Files trong Session
```http
GET /sessions/{session_id}/files
GET /sessions/{session_id}/file_content?file_path=example.py
POST /add_file?session_id={session_id}&file_path=example.py
```

### 6. X√≥a Session
```http
DELETE /sessions/{session_id}
```

## V√≠ d·ª• s·ª≠ d·ª•ng

### Python Client Example (Non-streaming)

```python
import requests

# T·∫°o session
response = requests.post("http://localhost:8000/sessions")
session_id = response.json()["session_id"]

# Chat v·ªõi Aider
chat_request = {
    "message": "Create a simple Python function to calculate fibonacci numbers",
    "session_id": session_id,
    "files": ["math_utils.py"],
    "model": "gpt-4o"
}

response = requests.post(
    "http://localhost:8000/chat",
    json=chat_request
)

result = response.json()
print(f"Response: {result['response']}")
print(f"Files edited: {len(result['edited_files'])}")
```

### Python Client Example (Streaming)

```python
import requests
import json

def handle_streaming_chat():
    # T·∫°o session
    response = requests.post("http://localhost:8000/sessions")
    session_id = response.json()["session_id"]
    
    # Streaming chat request
    chat_request = {
        "message": "Create a beautiful resume webpage with modern CSS",
        "session_id": session_id,
        "files": ["index.html"],
        "model": "deepseek/deepseek-coder",
        "stream": True  # Enable streaming
    }
    
    # G·ª≠i streaming request
    response = requests.post(
        "http://localhost:8000/chat",
        json=chat_request,
        stream=True,
        headers={
            "Accept": "text/event-stream",
            "Cache-Control": "no-cache"
        }
    )
    
    # X·ª≠ l√Ω streaming response
    for line in response.iter_lines(decode_unicode=True):
        if line:
            if line.startswith("event: "):
                event_type = line[7:]
            elif line.startswith("data: "):
                data_str = line[6:]
                try:
                    data = json.loads(data_str)
                    
                    if event_type == "start":
                        print(f"üü¢ {data.get('message', '')}")
                    elif event_type == "tool_output":
                        print(f"üîß {data.get('message', '')}")
                    elif event_type == "ai_output":
                        print(f"ü§ñ {data.get('message', '')}")
                    elif event_type == "file_write":
                        print(f"üìù File: {data.get('filename')} ({data.get('content_length')} chars)")
                    elif event_type == "complete":
                        print(f"üéâ Complete! Edited {len(data.get('edited_files', []))} files")
                        break
                        
                except json.JSONDecodeError:
                    pass

handle_streaming_chat()
```

### JavaScript/Node.js Example

```javascript
const axios = require('axios');

async function chatWithAider() {
    // T·∫°o session
    const sessionResponse = await axios.post('http://localhost:8000/sessions');
    const sessionId = sessionResponse.data.session_id;
    
    // Chat v·ªõi Aider
    const chatResponse = await axios.post('http://localhost:8000/chat', {
        message: 'Add error handling to this function',
        session_id: sessionId,
        files: ['app.js'],
        model: 'gpt-4o'
    });
    
    console.log('Response:', chatResponse.data.response);
    console.log('Edited files:', chatResponse.data.edited_files);
}

chatWithAider();
```

### cURL Example

```bash
# T·∫°o session
SESSION_ID=$(curl -s -X POST http://localhost:8000/sessions | jq -r '.session_id')

# Chat v·ªõi Aider
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Add docstrings to all functions in this file",
    "session_id": "'$SESSION_ID'",
    "files": ["example.py"],
    "model": "gpt-4o"
  }'
```

## Testing

### Test Non-streaming API
Ch·∫°y test script ƒë·ªÉ ki·ªÉm tra API:

```bash
python test_api.py
```

### Test Streaming API
Ch·∫°y test script ƒë·ªÉ ki·ªÉm tra streaming:

```bash
python test_streaming.py
```

### Test v·ªõi HTML Demo
M·ªü file `streaming_demo.html` trong browser ƒë·ªÉ test streaming API v·ªõi giao di·ªán web.

## Files ƒë∆∞·ª£c t·∫°o

- `api_server.py`: Main FastAPI server
- `api_io.py`: Custom InputOutput classes (bao g·ªìm StreamingApiInputOutput)
- `session_manager.py`: Session management
- `config.py`: Configuration settings
- `requirements_api.txt`: Dependencies
- `test_api.py`: Test script cho non-streaming API
- `test_streaming.py`: Test script cho streaming API
- `streaming_demo.html`: HTML demo client cho streaming
- `README_API.md`: Documentation n√†y

Test script s·∫Ω ki·ªÉm tra:
- Health check
- List models
- Create session
- Simple chat
- Chat with files
- Session management

## C·∫•u h√¨nh

C√°c c·∫•u h√¨nh c√≥ th·ªÉ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh trong `config.py`:

- `API_HOST`: Host ƒë·ªÉ bind API (m·∫∑c ƒë·ªãnh: "0.0.0.0")
- `API_PORT`: Port ƒë·ªÉ ch·∫°y API (m·∫∑c ƒë·ªãnh: 8000)
- `SESSION_TIMEOUT`: Th·ªùi gian timeout cho session (m·∫∑c ƒë·ªãnh: 3600 gi√¢y)
- `DEFAULT_MODEL`: Model m·∫∑c ƒë·ªãnh (m·∫∑c ƒë·ªãnh: "gpt-4o")
- `MAX_CONCURRENT_SESSIONS`: S·ªë session t·ªëi ƒëa (m·∫∑c ƒë·ªãnh: 100)

## L∆∞u √Ω

1. **API Keys**: ƒê·∫£m b·∫£o b·∫°n ƒë√£ c·∫•u h√¨nh ƒë√∫ng API keys cho c√°c model b·∫°n mu·ªën s·ª≠ d·ª•ng.

2. **Session Management**: Sessions s·∫Ω t·ª± ƒë·ªông b·ªã x√≥a sau khi timeout. S·ª≠ d·ª•ng endpoint delete ƒë·ªÉ x√≥a session th·ªß c√¥ng.

3. **File Paths**: T·∫•t c·∫£ file paths ph·∫£i l√† relative paths t·ª´ th∆∞ m·ª•c l√†m vi·ªác hi·ªán t·∫°i.

4. **Security**: Trong m√¥i tr∆∞·ªùng production, h√£y c·∫•u h√¨nh CORS v√† authentication ph√π h·ª£p.

5. **Performance**: API h·ªó tr·ª£ x·ª≠ l√Ω ƒë·ªìng th·ªùi nhi·ªÅu session, nh∆∞ng m·ªói session ch·ªâ x·ª≠ l√Ω m·ªôt request t·∫°i m·ªôt th·ªùi ƒëi·ªÉm.

## Troubleshooting

### API kh√¥ng kh·ªüi ƒë·ªông ƒë∆∞·ª£c
- Ki·ªÉm tra xem port 8000 c√≥ b·ªã chi·∫øm kh√¥ng
- ƒê·∫£m b·∫£o t·∫•t c·∫£ dependencies ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t
- Ki·ªÉm tra file config.py c√≥ ƒë√∫ng kh√¥ng

### Chat kh√¥ng ho·∫°t ƒë·ªông
- Ki·ªÉm tra API keys ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng ch∆∞a
- Xem logs ƒë·ªÉ bi·∫øt l·ªói c·ª• th·ªÉ
- ƒê·∫£m b·∫£o files t·ªìn t·∫°i v√† c√≥ quy·ªÅn ƒë·ªçc

### Session b·ªã m·∫•t
- Sessions c√≥ timeout, ki·ªÉm tra c·∫•u h√¨nh SESSION_TIMEOUT
- S·ª≠ d·ª•ng endpoint health check ƒë·ªÉ ki·ªÉm tra API c√≤n ho·∫°t ƒë·ªông kh√¥ng 